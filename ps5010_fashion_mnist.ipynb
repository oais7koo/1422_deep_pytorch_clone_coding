{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 신경망 맛보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심층 신경망 비교를 위해서 일단 심층신경망 생성(ConvNet이 적용안된 것)\n",
    "- fashion_mnist 데이터셋은 28*28 크기의 그레이 이미지 7만개로 구성\n",
    "- label은 0에서 9까지의 정수값을 가지는 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 5-1 라이브러리 호출\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 5-2 CPU 혹은 GPU 사용 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 5-3 데이터세트 내려받기\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='psdata/ps5060', download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='psdata/ps5060', download=True, train=False, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 5-4 데이터를 메모리에 로딩하기\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: psdata/ps5060\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0].__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0] # 튜플로 되어 있는데 첫번째 요소는 이미지 두번째는 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0]) # 이미지와 레이블을 함께 받아오는 것이기 때문에 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape # 그레이 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: psdata/ps5060\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset # 총 7만장중 6만장은 학습 1만장은 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 코드 5-5 분류에 사용될 클래스 정의 \n",
    "labels_map = {0:'T-shirt/top', 1:'Trouser', 2:'Pullover', 3:'Dress', 4:'Coat', 5:'Sandal', 6:'Shirt', 7:'Sneaker', 8:'Bag', 9:'Ankle boot'}\n",
    "\n",
    "fig = plt.Figure(figsize=(8,8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns * rows + 1):\n",
    "    img_xy = np.random.randint(len(train_dataset))\n",
    "    img = train_dataset[img_xy][0][0,:,:] # 3차원 배열 생성\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 5-6 심층 신경망 모델생성\n",
    "class FashionDNN(nn.Module): # nn은 딥러닝 모델(네트워크) 구성에 필요한 모듈이 모여있는 패키지\n",
    "    def __init__(self): # 클래스형태의 모델은 항상 torch.nn.Module을 상속받아야 한다.\n",
    "        super(FashionDNN,self).__init__() # 객체가 갖는 속성 값 초기화, super(FashionDNN) 은 FashionDNN의 부모 클래스(super)의 클래스를 상속받겠다는 것임\n",
    "        self.fc1 = nn.Linear(in_features=784, out_features=256) \n",
    "        self.drop = nn.Dropout(0.25) # 0.25만큼 텐서의 값이 0이됨, 0이 안되는 갓음 기존값의 1/(1-0.25)만큼 곱해져서 커짐\n",
    "        self.fc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=10)\n",
    "        \n",
    "    def forward(self,input_data): # 순전파 함수. 이름은 반드시 forward로 지정해야함\n",
    "        out = input_data.view(-1, 784) # view는 넘파이의 reshape 역할로 텐서 크기 변경 (-1, 784)은 (?, 784)의 크기로 변경(이차원 텐서로)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionDNN(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 코드 5-7 심층 신경망에서 필요한 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model = FashionDNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 분류문제에서 사용하는 손실 함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # 최적화 함수 경사하강법은 Adam 사용\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.5940324068069458, Accuracy: 83.31999969482422\n",
      "Iteration: 1000, Loss: 0.4805371165275574, Accuracy: 84.66999816894531\n",
      "Iteration: 1500, Loss: 0.3461099863052368, Accuracy: 84.13999938964844\n",
      "Iteration: 2000, Loss: 0.4197067618370056, Accuracy: 85.70999908447266\n",
      "Iteration: 2500, Loss: 0.27002808451652527, Accuracy: 85.7699966430664\n",
      "Iteration: 3000, Loss: 0.3119128346443176, Accuracy: 86.58999633789062\n"
     ]
    }
   ],
   "source": [
    "# 코드 5-8 심층 신경망을 이용한 모델 학습\n",
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader: # for를 이용해서 레코드를 하나씩 가지고 옴\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        train = Variable(images.view(100, 1, 28, 28)) # 100은 배치 수인듯\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        outputs = model(train) # 학습데이터를 모델에 적용\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50): # 50으로 나누었을 때 나머지가 0 이면 \n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device) # 모델이 데이터를 처리하기 위해서는 동일한 device에 있어야 함\n",
    "                labels_list.append(labels)\n",
    "                test = Variable(images.view(100, 1, 28, 28)) # autograd는 자동미분을 수행하는 파이토치 핵심 패키지로 자동 미분에 대한 값을 저장하기 위해서 tape를 사용\n",
    "                                                             # 순전파 단계에서 테이브는 수행하는 모든 연산을 저장함(그런데 이게 설명이 맞나)\n",
    "                                                             # autograd는 Variable을 사용해서 역전파를 위한 미분값을 자동으로 계산해줌\n",
    "                                                             # 자동미분을 게산하기 위해서는 torch.augograd 패키지 안에 있는 variable를 이용해야 동작함\n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels)\n",
    "            \n",
    "            accuracy = correct * 100 / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500): # 500만다\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}\".format(count, loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드5-9 합성곱 네트워크 생성\n",
    "class FashionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential( # __init__()에서 사용할 네트워크 모델을 정의해 줄 뿐 아닐\n",
    "                                     # forward()함수에서 구현될 순전파를 계층형태로 좀 더 가독성 높은 코드로 작성\n",
    "                                     # nn.Sequential은 계층을 차례로 쌓을 수 있도록 Wx + b와 같은 수식과 활성화 함수를 연결해주는 역할\n",
    "                                     # 특히 데이터가 각 계층을 순차적으로 지나갈때 사용하면 좋은 방법\n",
    "                                     # nn.Sequential은 여러 개의 계층을 하나의 컨테이너에 구현하는 방법\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1), # 합성곱층은 합성곱 연산을 통해서 이미지 특징 추출\n",
    "                                     # in_channels는 입력 채널의 수, out_channels는 출력 채널의 수, kernel_size는 필터의 크기\n",
    "            nn.BatchNorm2d(32), # 학습과정에서 각 배치 단위별로 데이터가 다양한 분포를 가지더라도 평균과 분산을 이용해서 정규화하는 것을 의미\n",
    "                                # 배치단위나 계층에 따라 입력 값의 분포가 모두 다르지만, 정규화를 통해 가우시안 형태로 만듦(평균 0, 표준편차 1)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 이미지 크기를 축소하는 용도로 사용\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600) # 클래스를 분류하기 위해서 이미지 형태의 데이터를 배열 형태로 변환\n",
    "                                                                   # Conv2d에서 사용된 하이퍼파라미터(패팅과 스트라이드 값)에 따라 출력크기가 달라짐\n",
    "                                                                   # 이렇게 줄어든 출력 크기는 최종적으로 분류를 담당하는 완전연결층으로 전달\n",
    "                                                                   # in_feature는 입력 데이터 크기\n",
    "        self.drop = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
    "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FashionCNN(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=2304, out_features=600, bias=True)\n",
      "  (drop): Dropout(p=0.25, inplace=False)\n",
      "  (fc2): Linear(in_features=600, out_features=120, bias=True)\n",
      "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 코드 5-10 합성곱 네트워크를 위한 파라미터 정의\n",
    "learning_rate = 0.001\n",
    "model = FashionCNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500, Loss: 0.442209392786026, Accuracy: 88.06999969482422%\n",
      "Iteration: 1000, Loss: 0.3772539496421814, Accuracy: 86.37999725341797%\n",
      "Iteration: 1500, Loss: 0.2946159839630127, Accuracy: 87.05000305175781%\n",
      "Iteration: 2000, Loss: 0.17134398221969604, Accuracy: 89.3499984741211%\n",
      "Iteration: 2500, Loss: 0.13496485352516174, Accuracy: 89.3499984741211%\n",
      "Iteration: 3000, Loss: 0.16990675032138824, Accuracy: 90.30000305175781%\n"
     ]
    }
   ],
   "source": [
    "# 코드 5-11 모델 학습 및 성능 평가\n",
    "\n",
    "num_epochs = 5\n",
    "count = 0\n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "predictions_list = []\n",
    "labels_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        train = Variable(images.view(100,1,28,28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        outputs = model(train)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        \n",
    "        if not (count % 50):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels_list.append(labels)\n",
    "                test = Variable(images.view(100,1,28,28))\n",
    "                outputs = model(test)\n",
    "                predictions = torch.max(outputs, 1)[1].to(device)\n",
    "                predictions_list.append(predictions)\n",
    "                correct += (predictions == labels).sum()\n",
    "                total += len(labels)\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            \n",
    "        if not (count % 500):\n",
    "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n",
    "                \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "992f425e58c3379c74963fffd7aafb953d75ec811aaddd2ee8a010590892053a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
